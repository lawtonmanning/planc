@InProceedings{KP13,
  author    = {Kuang, Da and Park, Haesun},
  title     = {Fast Rank-2 Nonnegative Matrix Factorization for Hierarchical Document Clustering},
  booktitle = {Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year      = {2013},
  series    = {KDD '13},
  pages     = {739--747},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2487606},
  doi       = {10.1145/2487575.2487606},
  file      = {:KP13.pdf:PDF},
  isbn      = {978-1-4503-2174-7},
  location  = {Chicago, Illinois, USA},
  numpages  = {9},
}

@Article{GKP15,
  author  = {N. {Gillis} and D. {Kuang} and H. {Park}},
  title   = {Hierarchical Clustering of Hyperspectral Images Using Rank-Two Nonnegative Matrix Factorization},
  journal = {IEEE Transactions on Geoscience and Remote Sensing},
  year    = {2015},
  volume  = {53},
  number  = {4},
  pages   = {2066-2078},
  month   = {April},
  doi     = {10.1109/TGRS.2014.2352857},
  file    = {:GKP15.pdf:PDF},
  issn    = {1558-0644},
}

@TechReport{EH+19-TR,
  author      = {Eswar, Srinivas and Hayashi, Koby and Ballard, Grey and Kannan, Ramakrishnan and Matheson, Michael A. and Park, Haesun},
  title       = {{PLANC}: Parallel Low Rank Approximation with Non-negativity Constraints},
  institution = {arXiv},
  year        = {2019},
  number      = {1909.01149},
  abstract    = {We consider the problem of low-rank approximation of massive dense non-negative tensor data, for example to discover latent patterns in video and imaging applications. As the size of data sets grows, single workstations are hitting bottlenecks in both computation time and available memory. We propose a distributed-memory parallel computing solution to handle massive data sets, loading the input data across the memories of multiple nodes and performing efficient and scalable parallel algorithms to compute the low-rank approximation. We present a software package called PLANC (Parallel Low Rank Approximation with Non-negativity Constraints), which implements our solution and allows for extension in terms of data (dense or sparse, matrices or tensors of any order), algorithm (e.g., from multiplicative updating techniques to alternating direction method of multipliers), and architecture (we exploit GPUs to accelerate the computation in this work).We describe our parallel distributions and algorithms, which are careful to avoid unnecessary communication and computation, show how to extend the software to include new algorithms and/or constraints, and report efficiency and scalability results for both synthetic and real-world data sets.},
  file        = {:EH+19-TR.pdf:PDF},
  url         = {https://arxiv.org/abs/1909.01149},
}

@Article{BCDH+14,
  Title                    = {Communication lower bounds and optimal algorithms for numerical linear algebra},
  Author                   = {Ballard, G. and Carson, E. and Demmel, J. and Hoemmen, M. and Knight, N. and Schwartz, O.},
  Journal                  = {Acta Numerica},
  Year                     = {2014},

  Month                    = {May},
  Pages                    = {1--155},
  Volume                   = {23},

  Abstract                 = {The traditional metric for the efficiency of a numerical algorithm has been the number of arithmetic operations it performs. Technological trends have long been reducing the time to perform an arithmetic operation, so it is no longer the bottleneck in many algorithms; rather, communication, or moving data, is the bottleneck. This motivates us to seek algorithms that move as little data as possible, either between levels of a memory hierarchy or between parallel processors over a network. In this paper we summarize recent progress in three aspects of this problem. First we describe lower bounds on communication. Some of these generalize known lower bounds for dense classical (O(n^3)) matrix multiplication to all direct methods of linear algebra, to sequential and parallel algorithms, and to dense and sparse matrices. We also present lower bounds for Strassen-like algorithms, and for iterative methods, in particular Krylov subspace methods applied to sparse matrices. Second, we compare these lower bounds to widely used versions of these algorithms, and note that these widely used algorithms usually communicate asymptotically more than is necessary. Third, we identify or invent new algorithms for most linear algebra problems that do attain these lower bounds, and demonstrate large speed-ups in theory and practice.},
  Annote                   = {Invited paper.},
  Doi                      = {10.1017/S0962492914000038},
  File                     = {BCDH+14.pdf:BCDH+14.pdf:PDF},
  ISSN                     = {1474-0508},
  Numpages                 = {155},
  Url                      = {http://journals.cambridge.org/article_S0962492914000038}
}

@Article{CH+07,
  Title                    = {Collective communication: theory, practice, and experience},
  Author                   = {Chan, E. and Heimlich, M. and Purkayastha, A. and van de Geijn, R.},
  Journal                  = {Concurrency and Computation: Practice and Experience},
  Year                     = {2007},
  Number                   = {13},
  Pages                    = {1749--1783},
  Volume                   = {19},

  Doi                      = {10.1002/cpe.1206},
  File                     = {CH+07.pdf:CH+07.pdf:PDF},
  ISSN                     = {1532-0634},
  Keywords                 = {collective communication, distributed-memory architecture, clusters},
  Publisher                = {John Wiley \& Sons, Ltd.},
  Url                      = {http://dx.doi.org/10.1002/cpe.1206}
}

@Article{TRG05,
  Title                    = {Optimization of Collective Communication Operations in {MPICH}},
  Author                   = {Thakur, Rajeev and Rabenseifner, Rolf and Gropp, William},
  Journal                  = {International Journal of High Performance Computing Applications},
  Year                     = {2005},
  Number                   = {1},
  Pages                    = {49--66},
  Volume                   = {19},

  Doi                      = {10.1177/1094342005051521},
  Eprint                   = {http://hpc.sagepub.com/content/19/1/49.full.pdf+html},
  File                     = {TRG05.pdf:TRG05.pdf:PDF},
  Url                      = {http://hpc.sagepub.com/content/19/1/49.abstract}
}

@InProceedings{GOS16,
  author    = {Gropp, William and Olson, Luke N. and Samfass, Philipp},
  title     = {Modeling {MPI} Communication Performance on SMP Nodes: Is It Time to Retire the Ping Pong Test},
  booktitle = {Proceedings of the 23rd European MPI Users' Group Meeting},
  year      = {2016},
  series    = {EuroMPI 2016},
  pages     = {41--50},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  doi       = {10.1145/2966884.2966919},
  file      = {:GOS16.pdf:PDF},
  isbn      = {9781450342346},
  location  = {Edinburgh, United Kingdom},
  numpages  = {10},
}

@Article{DKDP17,
  author    = {Du, Rundong and Kuang, Da and Drake, Barry and Park, Haesun},
  title     = {{DC-NMF}: nonnegative matrix factorization based on divide-and-conquer for fast clustering and topic modeling},
  journal   = {Journal of Global Optimization},
  year      = {2017},
  volume    = {68},
  number    = {4},
  pages     = {777--798},
  doi       = {10.1007/s10898-017-0515-z},
  file      = {:DKDP17.pdf:PDF},
  publisher = {Springer},
}

